---
output:
  html_document:
    theme: lumen
    toc_depth: 5
    toc_float: yes
  pdf_document:
    toc_depth: '5'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(knitr)
library(kableExtra)
library(pander)
```

# Ecological Niche Modeling Crash Course {.tabset .tabset-fade .tabset-pills}

## Background   
From 2017 - 2022, I continuously added to and created new workshop material for the "Using Digitized Collections-Based Data in Research: Applications for Ecology, Phylogenetics, and Biogeography" which the Soltis lab presents at the annual Botany meetings. Here is my current copy of working scripts. You can see the [latest workshop version here.](https://github.com/soltislab/BotanyENMWorkshops).




### Word bank   
| Term | Definition |
|:---------:|:-------------------------------------------|
| API | Application programming interface - this is the interface (the connection) between the user and the database |
 

## Setup

### Install
This workshop was made using R 3.6.2, we suggest you update your R. 
Prior to starting this workshop, you should have had the following packages installed.

```{r install, eval=FALSE, message=FALSE, warning=FALSE}
## Make a list of packages
list_of_packages <- c("dplyr", 
                      "tidyr",
                      "plyr", 
                      "spocc", 
                      "ridigbio",
                      "tibble", 
                      "tidyverse",
                      "rbison",
                      "CoordinateCleaner",
                      "lubridate",
                      "ggplot2",
                      "gtools",
                      "raster", 
                      "sp", 
                      "spatstat", 
                      "spThin", 
                      "fields", 
                      "ggspatial", 
                      "rgdal", 
                      "rangeBuilder", 
                      "sf", 
                      "dismo", 
                      "devtools", 
                      "ENMeval", 
                      "caret", 
                      "usdm", 
                      "stringr", 
                      "factoextra", 
                      "FactoMineR", 
                      "multcompView", 
                      "ggsci",
                      "gridExtra", 
                      "ecospat", 
                      "rJava", 
                      "viridis", 
                      "ENMTools", 
                      "ape", 
                      "RStoolbox", 
                      "hypervolume", 
                      "phytools",
                      "picante")

## If you do not have these packages already installed, install them by executing the code below:
new.packages <- list_of_packages[!(list_of_packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

## Checking version of packages
### Compare to version demo was made with
versiondf <- read.csv("data/setup/setup.csv", stringsAsFactors = FALSE)
current_version <- as.character(do.call(c, lapply(list_of_packages, packageVersion)))
versiondf$current_version <- current_version
updatelist <- versiondf[which(versiondf$version != versiondf$current_version), ]
### Update packages with old versions
lapply(as.character(updatelist$packages), install.packages, ask = FALSE)

## Make sure all packages load
lapply(list_of_packages, require, character.only = TRUE)

```

```{r eval=FALSE, message=FALSE, warning=FALSE}
# Install packages not in CRAN
library(devtools)
install_github('johnbaums/rmaxent')
install_github("marlonecobos/kuenm")
```

### What are these packages?

[**tidyverse**](https://www.tidyverse.org/) is a collection of R packages that are used for "everyday data analysis" including **ggplot2**, **dplyr**, **tidyr**, **readr**, **purr**, **tibble**, **stringr**, **forcats**. We use dplyr and ggplot2 throughout many of the R scripts.

**ridigbio** is an R package that queries the iDigBio API.

**spocc** queries data from GBIF, USGS' Biodiversity Information Serving Our Nation (BISON), iNaturalist, Berkeley Ecoinformatics Engine, eBird, iDigBio, VertNet, Ocean Biogeographic Information System (OBIS), and Atlas of Living Australia (ALA).

**RCurl** and **rjson** are used to query an application programming interface (API), or an online database.

Geospatial packages include **sp**, **raster**, **maptools**, **maps**, **rgdal**, **RStoolbox**, and **mapproj**.

**ggplot2** is used to plot and visualize data. **ggbiplot** is an add on to ggplot2.

**ENMTools**, **ENMeval**, and **dismo** are specific to ecological niche modeling.

**hypervolume** and **caret** have functions related to statistics.

**phytools** and **picante** are related to phylogenetics.

**factoextra** and **FactoMiner** are used for statistics related to a principal components analysis.

------------------------------------------------------------------------

------------------------------------------------------------------------

### Troubleshooting

-   For **spatstat** make sure xcode is installed on OS.

```{r eval=FALSE}
system("xcode-select --install")
```

-   **spThin** and **fields** do not compile from source!


-   If you are still having issues installing ggbiplot, you may have to uninstall the package 'backports' and reset R.

------------------------------------------------------------------------

------------------------------------------------------------------------


This exercise requires the package **ENMTools**. This package requires Java (and the Oracle Java JDK) and that the maxent.jar file is in the folder that contains the **dismo** package (this package is a dependency of ENMTools). To find out where to put the jar file, run the command:

```{r eval=FALSE}
system.file("java", package="dismo")
```

Once you have your java and maxent file set, you are ready to go! If you have more issues, find some [help here](https://github.com/MTFA/CohortEx/wiki/Run-rJava-with-RStudio-under-OSX-10.10,-10.11-(El-Capitan)-or-10.12-(Sierra))

To download the jar file to the right directory ---

```{r message=FALSE, warning=FALSE, eval=FALSE}
devtools::install_github("johnbaums/rmaxent")
rmaxent::get_maxent(version = "latest", quiet = FALSE)
```

The previous step may mask *rgdal!* Make sure to reload it!

For rJava, the newest package requires R >= 3.6.0  
dismo only requires rJava >= 0.9-7, download [0.9.7 here](https://cran.r-project.org/src/contrib/Archive/rJava/)      

If you are experiencing errors with rJava:

```{r eval=FALSE}
## Remove rJava
remove.packages(rJava)
## Update your R Java configuration 
system("sudo R CMD javareconf")
## Restart R and check to see if the path matches
Sys.getenv("DYLD_FALLBACK_LIBRARY_PATH")
## Reinstall rJava
install.packages("rJava")
library(rJava)
```

If you are **still** having issues with rJava - check to see if you are using Java 12 (this should be included in the error message):

```{r eval=FALSE}
system("java -version")
```

The initial release of java 12 does not work - install an old version instead.
To install an old version, navigate to the Oracle website or  use homebrew.

```{r eval=FALSE}
system("brew cask install homebrew/cask-versions/java11")
```

Restart R and redo the previous steps. Required: uninstall the newer versions of java prior to repeating and restart R after.

```{r eval=FALSE}
## Uninstall Java 12, then repeat the following
## Remove rJava
remove.packages(rJava)
## Update your R Java configuration 
system("sudo R CMD javareconf")
## Restart R and check to see if the path matches
Sys.getenv("DYLD_FALLBACK_LIBRARY_PATH")
## Reinstall rJava
install.packages("rJava")
library(rJava)
```

More debugging: Check out [jerrybreak's comment from 12/30/2021](https://github.com/rstudio/rstudio/issues/2254#issuecomment-580886272).       

If you have additional issues, please let us know!

## Download Occurrence Data

ML Gaynor.

### Load packages

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(spocc) 
library(ridigbio) 
library(rbison)
```

### Load functions

This is a function I created with Natalie Patten. It will be part of her R package gatoRs (Geographic And Taxonomic Occurrence R-based Scrubbing).

```{r message=FALSE, warning=FALSE}
source("functions/gators.R")
```

### Data download from iDigBio

#### Search for the species Galax urceolata.

```{r}
iDigBio_GU <- idig_search_records(rq=list(scientificname="Galax urceolata"))
```

#### Search for the family Diapensiaceae.

```{r}
iDigBio_GU_family <- idig_search_records(rq=list(family="Diapensiaceae"), limit=1000)
```

**What if you want to read in all the points for a family within an extent?**

**Hint**: Use the [iDigBio portal](https://www.idigbio.org/portal/search) to determine the bounding box for your region of interest.       

The bounding box delimits the geographic extent. 

```{r}
rq_input <- list("scientificname"=list("type"="exists"),
                 "family"="Diapensiaceae", 
                 geopoint=list(
                   type="geo_bounding_box",
                   top_left=list(lon = -98.16, lat = 48.92),
                   bottom_right=list(lon = -64.02, lat = 23.06)
                   )
                 )
```

Search using the input you just made

```{r}
iDigBio_GU_family_USA <- idig_search_records(rq_input, limit=1000)
```

#### Save as csv files

```{r}
write.csv(iDigBio_GU, "data/download/iDigBio_GU_20220505.csv", 
          row.names = FALSE)
write.csv(iDigBio_GU_family, "data/download/iDigBio_GU_family_20220505.csv", 
          row.names = FALSE)

```

### Data download using spocc\_combined

#### Make synonym lists

```{r}
Shortia_galacifolia <- c("Shortia galacifolia", "Sherwoodia galacifolia")
Galax_urceolata <- c("Galax urceolata", "Galax aphylla")
Pyxidanthera_barbulata <- c("Pyxidanthera barbulata","Pyxidanthera barbulata var. barbulata")
Pyxidanthera_brevifolia <- c("Pyxidanthera brevifolia", "Pyxidanthera barbulata var. brevifolia")
```

#### Use the spocc\_combine function
This function downloads records for all names listed from iDigBio, GBIF, and BISON. It keeps specific columns from each database.

```{r}
sspocc_combine(Shortia_galacifolia,
               "data/download/raw/Shortia_galacifolia_raw_20220505.csv")
spocc_combine(Galax_urceolata, 
              "data/download/raw/Galax_urceolata_raw_20220505.csv")
spocc_combine(Pyxidanthera_barbulata, 
              "data/download/raw/Pyxidanthera_barbulata_raw_20220505.csv")
spocc_combine(Pyxidanthera_brevifolia,
              "data/download/raw/Pyxidanthera_brevifolia_raw_20220505.csv")
```


Here is a table of the columns returned for each species in **spocc_combine**:  
```{r echo=FALSE}
column <- c("name",  "basis",  "date",  "institutionID",  "collectionCode",  "collectionID",  "country",  "county",  "state",  "locality",  "Latitude",  "Longitude",  "ID",  "coordinateUncertaintyInMeters",  "habitat",  "prov",  "spocc_*")
description <- c("scientific name, http://rs.tdwg.org/dwc/terms/scientificName", 
                 "basis of record, http://rs.tdwg.org/dwc/terms/basisOfRecord", 
                 "event data, http://rs.tdwg.org/dwc/terms/eventDate",
                 "institution ID, http://rs.tdwg.org/dwc/terms/institutionID ", 
                 "collection code, http://rs.tdwg.org/dwc/terms/collectionCode", 
                 "collection ID, http://rs.tdwg.org/dwc/terms/collectionID",
                 "country, http://rs.tdwg.org/dwc/terms/country", 
                 "county, http://rs.tdwg.org/dwc/terms/county", 
                 "stateprovince, http://rs.tdwg.org/dwc/terms/stateProvince", 
                 "http://rs.tdwg.org/dwc/terms/locality or http://rs.tdwg.org/dwc/terms/verbatimLocality", 
                 "http://rs.tdwg.org/dwc/terms/decimalLatitude",
                 "http://rs.tdwg.org/dwc/terms/decimalLongitude ", 
                 "idigbio = uuid, gbif = key, bison = occurrenceID", 
                 "http://rs.tdwg.org/dwc/terms/coordinateUncertaintyInMeters", 
                 "http://rs.tdwg.org/dwc/iri/habitat", 
                 "indicates who provided the data: gbif, bison, or idigbio",
                 "these columns are returned from the spocc::occ2df function")

metadatainfo <- data.frame(Column = column, Description = description)
kable(metadatainfo) %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 11)) %>%
   scroll_box(width = "100%", height = "200px")

```

  
## Occurrence Data Cleaning

ML Gaynor.

### Load Packages

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(raster)
library(sp)
library(sf)
library(spatstat)
library(spThin)
library(fields)
library(lubridate)
library(CoordinateCleaner)
library(ggplot2)
library(ggspatial)
```

### Load functions

This is a function I created with Natalie Patten. It will be part of her R package gatoRs (Geographic And Taxonomic Occurrence R-based Scrubbing).

```{r message=FALSE, warning=FALSE}
source("functions/gators.R")
```

### Read in downloaded data frame

```{r}
rawdf <- read.csv("data/download/raw/Shortia_galacifolia_raw_20210614.csv")
```

### Cleaning

#### Inspect the data frame

**What columns are included?**

```{r}
names(rawdf)
```

**How many observations do we start with?**

```{r}
nrow(rawdf)
```

### [ 1. Resolve taxon names ]{style="color: blue;"}

Inspect scientific names included in the raw df.

```{r}
unique(rawdf$name)
```

Create a list of accepted names based on the name column in your data frame

```{r}
search <-  c("Shortia galacifolia", "Sherwoodia galacifolia")
```

Filter to only include accepted name:

```{r}
df <-  filter_fix_names(rawdf, listofsynonyms = search, acceptedname = "Shortia galacifolia")
```

**How many observations do we have now?**

```{r}
nrow(df)
```

### [ 2. Decrease number of columns ]{style="color: blue;"}

Merge the two locality columns

```{r}
df$Latitude <- dplyr::coalesce(df$Latitude, df$spocc.latitude)
df$Longitude <- dplyr::coalesce(df$Longitude, df$spocc.longitude)
```

**If spocc didn't download any lat/longs and there are 0 values in the spocc.latitude or spocc.longitude columns, skip this step**\
**The two columns could have different classes, if so, find the [fix here](https://gist.github.com/mgaynor1/6a45ae7a1604069b5d9b5d10767ba326)**

Merge the two date columns

```{r}
df$date <- dplyr::coalesce(df$date, df$spocc.date)
```

Subset the columns

```{r}
df <- df %>%
      dplyr::select(ID = ID, 
                    name = new_name, 
                    basis = basis, 
                    coordinateUncertaintyInMeters = coordinateUncertaintyInMeters, 
                    informationWithheld = informationWithheld, 
                    lat = Latitude, 
                    long = Longitude, 
                    date = date)
```

### [ 3. Clean localities ]{style="color: blue;"}

Filtering out NA's

```{r}
df <- df %>%
      filter(!is.na(long)) %>%
      filter(!is.na(lat))
```

**How many observations do we have now?**

```{r}
nrow(df)
```

#### Precision

Round to two decimal places

```{r}
df$lat <- round(df$lat, digits = 2)
df$long <- round(df$long, digits = 2)
```

#### Remove unlikely points

Remove points at 0.00, 0.00

```{r}
df <- df %>%
      filter(long != 0.00) %>%
      filter(lat != 0.00)
```

Remove coordinates in cultivated zones, botanical gardens, and outside our desired range

```{r}
df <- CoordinateCleaner::cc_inst(df, 
              lon = "long", 
              lat = "lat", 
              species = "name")
```

Next, we look for geographic outliers and remove outliers.

```{r}
df <- CoordinateCleaner::cc_outl(df, 
              lon = "long", 
              lat = "lat", 
              species = "name")

```

**How many observations do we have now?**

```{r}
nrow(df)
```

### [ 4. Remove Duplicates ]{style="color: blue;"}

#### Fix dates

Parse dates into the same format

```{r}
df$date <- lubridate::ymd(df$date)
```

Separate date into year, month, day

```{r}
df <- df %>%
      mutate(year = lubridate::year(date), 
             month = lubridate::month(date), 
             day = lubridate::day(date))
```

#### Remove rows with identical lat, long, year, month, and day

```{r}
df <- distinct(df, lat, long, year, month, day, .keep_all = TRUE)
```

**How many observations do we have now?**

```{r}
nrow(df)
```

### [ 5. Spatial Correction ]{style="color: blue;"}

Maxent will only retain one point per pixel. To make the ecological niche analysis comparable, we will retain only one point per pixel.    
   
#### One point per pixel      

##### Read in raster file   

```{r}
bio1 <- raster("data/climate_processing/bioclim/bio_1.tif")
```

##### Set resolution

```{r}
rasterResolution <- max(res(bio1))
```

##### Filter

Remove a point which nearest neighbor distance is smaller than the resolution size (aka remove one point in a pair that occurs within one pixel)

```{r}
while(min(nndist(df[,6:7])) < rasterResolution){
  nnD <- nndist(df[,6:7])
  df <- df[-(which(min(nnD) == nnD) [1]), ]
}
```

**How many observations do we have now?**

```{r}
nrow(df)
```

#### Spatial thinning     

Reduce the effects of sampling bias using randomization approach.     

##### Calculate minimum nearest neighbor distance in km

```{r}
nnDm <- rdist.earth(as.matrix(data.frame(lon = df$long, lat = df$lat)), miles = FALSE, R = NULL)
nnDmin <- do.call(rbind, lapply(1:5, function(i) sort(nnDm[,i])[2]))
min(nnDmin)
```

##### Identify points to keep using spThin

```{r}
keep <- spThin::thin(loc.data =  df, 
        verbose = FALSE, 
        long.col = "long", 
        lat.col = "lat",
        spec.col = "name",
        thin.par = 0.002, # Studies found 2m distance was enough to collect unique genets
        reps = 1, 
        locs.thinned.list.return = TRUE, 
        write.files = FALSE)[[1]]
```

##### Filter df to only include those lat/long that have been kept using spThin

```{r}
df <- df %>%
       filter((lat %in% keep$Latitude +
                long %in% keep$Longitude) == 2)
nrow(df)
```

### [ 6. Plot Cleaned Records ]{style="color: blue;"}   
   
#### Make points spatial    

```{r}
df_fixed <- st_as_sf(df, coords = c("long", "lat"), crs = 4326)
```

#### Set basemap

```{r}
USA <- borders(database = "usa", colour = "gray50", fill = "gray50")
state <- borders(database = "state", colour = "black", fill = NA)
```

#### Plot

Here we are using *ggplot2* and **ggspatial** to plot our occurrence records. We are using two basemaps, USA and state. The *geom\_point* function adds our points based on long and lat, and colors them blue. We set the coordinate visualization space with *coord\_sf*. We fixed the x and y labels. Finally, we added a scale and north arrow.

```{r}
simple_map <- ggplot() +
              USA +
              state +
              geom_sf(df_fixed, 
                       mapping = aes(col = name), 
                       col = "blue") +
              coord_sf(xlim = c(min(df$long) - 3, max(df$long) + 3),
                       ylim = c(min(df$lat) - 3, max(df$lat) + 3)) +
              xlab("Longitude") +
              ylab("Latitude") +
              annotation_scale() +
              annotation_north_arrow(height = unit(1, "cm"), 
                                     width = unit(1, "cm"), 
                                     location = "tl")
simple_map

```

### [ 7. Save Cleaned.csv ]{style="color: blue;"}

```{r}
write.csv(df, "data/cleaning_demo/Shortia_galacifolia_20210618-cleaned.csv", row.names = FALSE)

```

### [ 8. Make maxent ready ]{style="color: blue;"}

#### Read in all cleaned files

```{r eval=FALSE, include=TRUE}
alldf <- list.files("data/cleaning_demo/raw/", full.names = TRUE, 
                    recursive = FALSE, include.dirs = FALSE, pattern = "*.csv")
alldf <- lapply(alldf, read.csv)
alldf <- do.call(rbind, alldf)
```

#### Plot all records    
Visually inspect records to verify no additional records should be removed. 

```{r}
## Plot all records
### Make points spatial 
alldf_fixed <- st_as_sf(alldf, coords = c("long", "lat"), crs = 4326)

### Set basemap
USA <- borders(database = "usa", colour = "gray50", fill = "gray50")
state <- borders(database = "state", colour = "black", fill = NA)

### Plot 
all_map <- ggplot() +
            USA +
            state +
            geom_sf(alldf_fixed, 
                    mapping = aes(col = factor(name))) +
            coord_sf(xlim = c(min(alldf$long) - 3, max(alldf$long) + 3),
                     ylim = c(min(alldf$lat) - 3, max(alldf$lat) + 3)) +
            xlab("Longitude") +
            ylab("Latitude") +
            annotation_scale() +
            annotation_north_arrow(height = unit(1, "cm"), 
                                   width = unit(1, "cm"), 
                                   location = "tl")
all_map
```



#### Select needed columns

```{r eval=FALSE, include=TRUE}
alldf <- alldf %>%
         dplyr::select(name, lat, long)
```

#### Save Maxent.csv

```{r eval=FALSE, include=TRUE}
write.csv(alldf, "data/cleaning_demo/maxent_ready/diapensiaceae_maxentready_20210618.csv", row.names = FALSE)

```

## Climate Processing

Climate layer processing.\
Modified and created by ML Gaynor.\
Based on code by Mike Belitz ([mbelitz/Odo\_SDM\_Rproj](https://github.com/mbelitz/Odo_SDM_Rproj)).

### Load Packages

```{r message=FALSE, warning=FALSE}
library(raster)
library(gtools)
library(dplyr)
library(rgdal)
library(sp)
library(rangeBuilder)
library(sf)
library(caret)
library(usdm)
library(dismo)
library(stringr)
```

### Load functions     
Based on code by Mike Belitz ([mbelitz/Odo\_SDM\_Rproj](https://github.com/mbelitz/Odo_SDM_Rproj)).
```{r}
source("functions/VIFLayerSelect.R")
```

### Load bioclim layers

```{r}
biolist <- list.files("data/climate_processing/bioclim/", pattern = "*.tif", full.names = TRUE)
```

Order list using **gtools**.

```{r}
biolist <- mixedsort(sort(biolist))
```

Load rasters as a stack.

```{r}
biostack <- raster::stack(biolist)
```

### Load occurrence records

And fix the name column class and make sure it is a character.

```{r}
alldf <- read.csv("data/cleaning_demo/maxent_ready/diapensiaceae_maxentready_20210625.csv")
alldf$name <- as.character(alldf$name)
```

### Present Layers - all

Here we will make the projection layers, or the layers which include shared space. First, we have to define the accessible space.

#### Make into a spatial point data frame

```{r}
alldfsp <- alldf
coordinates(alldfsp) <- ~ long + lat
proj4string(alldfsp) <- CRS("+proj=longlat +datum=WGS84")
```

#### Create alpha hull

```{r}
hull <- getDynamicAlphaHull(x = alldfsp@coords, 
                             fraction = 1, # min. fraction of records we want included
                             partCount = 1, # number of polygons
                             initialAlpha = 20, # initial alpha size, 20m
                             clipToCoast = "terrestrial",
                             proj = "+proj=longlat +datum=WGS84")
```

#### Visualize

```{r}
plot(hull[[1]], col=transparentColor('gray50', 0.5), border = NA)
points(x = alldf$long, y = alldf$lat, cex = 0.5, pch = 3)
```

#### Add buffer to hull

##### Transform into CRS related to meters

```{r}
hullTrans <- spTransform(hull[[1]], "+proj=cea +lat_ts=0 +lon_0=0")
alldfspTrans <- spTransform(alldfsp, "+proj=cea +lat_ts=0 +lon_0")
```

##### Calculate buffer size

Here we take the 80th quantile of the max distance between points

```{r}
buffDist <- quantile(x = (apply(spDists(alldfspTrans), 2,
                                FUN = function(x) sort(x)[2])), 
                     probs = 0.80, na.rm = TRUE) 

```

##### Buffer the hull

```{r}
buffer_m <- buffer(x = hullTrans, width = buffDist, dissolve = TRUE)
buffer <- spTransform(buffer_m, "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
```

##### Visualize

```{r}
plot(buffer, col=transparentColor('gray50', 0.5), border = NA)
points(x = alldf$long, y = alldf$lat, cex = 0.5, pch = 3)
```

### Mask and crop bioclim layers

```{r}
path <- "data/climate_processing/all/"
end <- ".asc"
for(i in 1:length(biolist)){
    # Subset raster layer
    rast <- biostack[[i]]
    # Setup file names
    name <- names(rast)
    out <- paste0(path, name)
    outfile <- paste0(out, end)
    # Crop and mask
    c <- crop(rast, extent(buffer))
    c <- mask(c, buffer)
    # Write raster
    writeRaster(c, outfile, format = "ascii", overwrite = TRUE)
}
```

### Select layers for MaxEnt

We only want to include layers that are not highly correlated. To assess which layers we will include, we can look at the pearson correlation coefficient among layers.   

#### Stack all layers   

```{r}
clippedlist <- list.files("data/climate_processing/all/", pattern = "*.asc", full.names = TRUE)
clippedlist <- mixedsort(sort(clippedlist))
clippedstack <- raster::stack(clippedlist)
```

#### Then calculate the correlation coefficient

```{r}
corr <- layerStats(clippedstack, 'pearson', na.rm=TRUE)
```

Isolate only the pearson correlation coefficient and take absolute value.    

```{r}
c <- abs(corr$`pearson correlation coefficient`)
```

#### Write file and view in excel    

```{r}
write.csv(c, "data/climate_processing/correlationBioclim.csv", row.names = FALSE)
```

Highly correlated layers (\> \|0.80\|) can impact the statistical significance of the niche models and therefore must be removed.

#### Randomly select variables to remove

```{r}
envtCor <- mixedsort(sort(findCorrelation(c, cutoff = 0.80, names = TRUE, exact = TRUE)))
envtCor
```

### Variable inflation factor (VIF)

VIF can detect for multicollinearity in a set of multiple regression variables. Run a simple maxent model for every species and calculate the average permutation contribution.      

##### Run preliminary MaxEnt models     
Loop through each species and save permutation importance in list.    
**Warning:** This will print warnings even when it works fine.     

```{r message=FALSE, warning=FALSE, eval=FALSE}
set.seed(195)
m <- c()
for(i in  1:length(unique(alldf$name))){
    species <- unique(alldf$name)[i]
    spp_df <-  alldf %>%
               dplyr::filter(name == species)
    coordinates(spp_df) <- ~ long + lat
    model <- maxent(x = clippedstack, p = coordinates(spp_df), 
                    progress = "text", silent = FALSE) 
    m[[i]] <- vimportance(model)
}
```

#### Bind the dataframes

```{r eval=FALSE}
mc <- do.call(rbind, m)
```

#### Calculate the mean and rename columns

```{r eval=FALSE}
mc_average <- aggregate(mc[, 2], list(mc$Variables), mean)
mc_average <- mc_average %>%
              dplyr::select(Variables = Group.1, permutation.importance = x)
mc1 <- mc_average
```

#### Select Layers

Use VIF and the MaxEnt permutation importance to select the best variables for your model. Note, this leads to different layers when the models are rerun without setting seed due to permutations being random.

```{r eval=FALSE}
selectedlayers <- VIF_layerselect(clippedstack, mc_average)
mixedsort(sort(names(selectedlayers)))
```


##### Correct set for workshop purposes
Since this can vary per system (despite setting seed), we added this line to keep our files consistent for the workshop
```{r}
sl <- c("bio_3", "bio_7", "bio_8", "bio_9", "bio_14", "bio_15", "bio_18", "elev")
selectedlayers <- raster::subset(clippedstack, sl)
```


### Copy selected layers

Move selected layers to "Present\_Layers/all/" for use in MaxEnt later.

```{r}
for(i in 1:length(names(selectedlayers))){
    name <- names(selectedlayers)[i]
    from <- paste0("data/climate_processing/all/", name, ".asc")
    to <- paste0("data/climate_processing/PresentLayers/all/", name, ".asc")
    file.copy(from, to,
              overwrite = TRUE, recursive = FALSE, 
              copy.mode = TRUE)
}
```

### Create Species Training Layers

```{r eval=FALSE, include=TRUE}
for(i in 1:length(unique(alldf$name))){
    species <- unique(alldf$name)[i]
    # Subset species from data frame
    spp_df <-  alldf %>%
               dplyr::filter(name == species)
    # Make spatial
    coordinates(spp_df) <- ~ long + lat
    proj4string(spp_df) <- CRS("+proj=longlat +datum=WGS84")
    
    ## Create alpha hull
    sphull <- getDynamicAlphaHull(x = spp_df@coords, 
                                fraction = 1, # min. fraction of records we want included
                                partCount = 1, # number of polygons
                                initialAlpha = 20, # initial alpha size, 20m
                                clipToCoast = "terrestrial",
                                proj = "+proj=longlat +datum=WGS84")
    
    ### Transform into CRS related to meters
    sphullTrans <- spTransform(sphull[[1]], "+proj=cea +lat_ts=0 +lon_0=0")
    spp_dfTrans <- spTransform(spp_df, "+proj=cea +lat_ts=0 +lon_0")
    
    ### Calculate buffer size
    #### Here we take the 80th quantile of the max distance between points
    spbuffDist <- quantile(x = (apply(spDists(spp_dfTrans), 2, FUN = function(x) sort(x)[2])), 
                         probs = 0.80, na.rm = TRUE) 
    
    ### Buffer the hull
    spbuffer_m <- buffer(x = sphullTrans, width = spbuffDist, dissolve = TRUE)
    spbuffer <- spTransform(spbuffer_m,
                            "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
    ### Crop and Mask
    spec <- gsub(" ", "_", species)
    path <- paste0("data/climate_processing/PresentLayers/", spec,"/")
    end <- ".asc"
    for(j in 1:length(names(selectedlayers))){
        # Subset raster layer
        rast <- selectedlayers[[j]]
        # Setup file names
        name <- names(rast)
        out <- paste0(path, name)
        outfile <- paste0(out, end)
        # Crop and mask
        c <- crop(rast, extent(buffer))
        c <- mask(c, buffer)
        # Write raster
        writeRaster(c, outfile, format = "ascii", overwrite = TRUE)
    }
}
```

## Point Based

Ecological analysis using points. This is based off scripts created by Hannah Owens and James Watling, and Anthony Melton.\
Modified and created by ML Gaynor.

### Load Packages

```{r message=FALSE, warning=FALSE}
library(raster)
library(dplyr)
library(tidyr)
library(gtools)
library(factoextra)
library(FactoMineR)
library(multcompView)
library(ggsci)
library(gridExtra)
library(ggplot2)
library(ecospat)
library(dismo)
```

#### Load functions   

This function is from [vqv/ggbiplot](https://github.com/vqv/ggbiplot).   
```{r}
source("functions/ggbiplot_copy.R")
```


### Load data file

```{r}
alldf <- read.csv("data/cleaning_demo/maxent_ready/diapensiaceae_maxentready_20210625.csv")
```

### Raster layers

```{r}
list <- list.files("data/climate_processing/PresentLayers/all", full.names = TRUE, recursive = FALSE) 
list <- mixedsort(sort(list))
envtStack <- stack(list)
```

------------------------------------------------------------------------

### ENM - Realized Niche

#### Extract value for each point

For each occurence record, extract the value for each bioclim variables using the package raster.

```{r}
ptExtracted <- raster::extract(envtStack, alldf[3:2])
```

#### Convert to data frame

```{r}
ptExtracteddf <- as.data.frame(ptExtracted)
```

#### Add species name

```{r}
ptExtracteddf <- ptExtracteddf %>%
                 dplyr::mutate(name = as.character(alldf$name), x = alldf$long, y = alldf$lat)
```

#### Drop any NA

```{r}
ptExtracteddf <- ptExtracteddf %>% 
                 tidyr::drop_na(bio_3, bio_7, bio_8, bio_9, bio_14, bio_15, bio_18, elev)
```

### PCA

#### Create two dataframes.

```{r}
data.bioclim <- ptExtracteddf[, 1:8]
data.species <- ptExtracteddf[, 9]
```

#### Using only the bioclim columns to run the principal components analysis.

```{r}
data.pca <- prcomp(data.bioclim, scale. = TRUE) 
```

#### Understanding the PCA - Optional

When you use the command prcomp your loading variables show up as rotational variables. Thanks to a really great answer on [stack overflow](https://stackoverflow.com/questions/43407859/how-do-i-find-the-link-between-principal-components-and-raw-datas-variables) you can even convert the rotational variable to show the relative contribution.

```{r}
loadings <- data.pca$rotation
summary(loadings)
```

There are two options to convert the loading to show the relative contribution, they both give the same answer so either can be used.     

##### Option 1   

```{r}
loadings_relative_A <- t(t(abs(loadings))/rowSums(t(abs(loadings))))*100
loadings_relative_A
```

##### Option 2   

```{r}
loadings_relative_B <- sweep(x = abs(loadings), 
                             MARGIN = 2, 
                             STATS = colSums(abs(loadings)), FUN = "/")*100
loadings_relative_B


```

#### Plotting the PCA

##### Set theme  

First, I made a theme to change the background of the plot. Next, I changed the plot margins and the text size.

```{r}
theme <- theme(panel.background = element_blank(),
               panel.border=element_rect(fill=NA),
               panel.grid.major = element_blank(),
               panel.grid.minor = element_blank(),
               strip.background=element_blank(),
               axis.ticks=element_line(colour="black"),
               plot.margin=unit(c(1,1,1,1),"line"), 
               axis.text = element_text(size = 12), 
               legend.text = element_text(size = 12), 
               legend.title = element_text(size = 12),
               text = element_text(size = 12))
```

##### Set color palette    

```{r}
pal <- pal_locuszoom()(4)
```

##### ggbiplot   

Next, use ggbiplot where obs.scale indicates the scale factor to apply to observation, var.scale indicates the scale factor to apply to variables, ellipse as TRUE draws a normal data ellipse for each group, and circle as TRUE draws a correlation circle.

```{r fig.height=4, fig.width=8, message=FALSE, warning=FALSE}
g <- ggbiplot(data.pca, obs.scale = 1, var.scale = 1, 
              groups = data.species, ellipse = TRUE, circle = TRUE) +
     scale_color_manual(name = '', values = pal) +
     theme(legend.direction = 'vertical', legend.position = 'right', 
           legend.text = element_text(size = 12, face = "italic")) +
     theme
 
g
```

------------------------------------------------------------------------

### ANOVA

Simple function to run an ANOVA and a post-hoc Tukey-HSD test

```{r}
stat.test <- function(data = ptExtracteddf, x = "name", y){
    bioaov <- aov(as.formula(paste0(y,"~",x)), data = data) 
    TH <- TukeyHSD(bioaov, "name")
    m <- multcompLetters(TH$name[,4])
    groups <- data.frame(groups = m$Letters, name = names(m$Letters))
    return(groups)
}
```

#### Run for bio\_3 only

```{r}
bio3aovplot <- ggplot(ptExtracteddf, aes(x = name, y = bio_3)) +
               geom_boxplot(aes(fill = name)) +
               scale_color_manual(name = '', values = pal) +
               geom_text(data = stat.test(y = "bio_3"), 
                        mapping = aes(x = name,
                                      y = max(ptExtracteddf["bio_3"]+1), 
                                      label = groups), 
                        size = 5, inherit.aes = FALSE) +
               theme(axis.text.x = element_text(angle = 90, size = 8, face = 'italic'))
bio3aovplot

```

#### Loop through all variables

```{r fig.height=10, fig.width=10}
variablelist <- colnames(ptExtracteddf)[1:8]
plotlist <- c()
for(i in 1:8){
  bio <- variablelist[i]
  tempdf <- ptExtracteddf %>%
            dplyr::select(name, variablelist[i])
  plotlist[[i]] <- ggplot(tempdf, aes(x = name, y = tempdf[,2])) +
                    geom_boxplot(aes(fill = name)) +
                    scale_colour_manual(name = 'Species', values = pal) +
                    geom_text(data = stat.test(y = variablelist[i]), 
                              mapping = aes(x = name,
                                            y = max(tempdf[,2]+1), 
                                            label = groups), 
                              size = 5, inherit.aes = FALSE) +
                    scale_x_discrete(labels = c('G', 'Pba','Pbr', 'S')) +
                    ggtitle(label = paste0(variablelist[i])) +
                    ylab(paste0(variablelist[i])) +
                    theme(legend.position = "none")
}

gridExtra::grid.arrange(grobs = plotlist)
```

------------------------------------------------------------------------

### Ecospat Niche Overlap and Niche Equivalency

#### Set up background points

```{r message=FALSE, warning=FALSE}
bg1 <- randomPoints(mask = envtStack, n = 1000, p = alldf[,3:2])
bg1.env <- raster::extract(envtStack, bg1)
bg1.env <- data.frame(bg1.env)
allpt.bioclim <- rbind(bg1.env, data.bioclim)  
```

#### dudi.PCA to reduce variables

```{r}
pca.env <- dudi.pca(allpt.bioclim,
                    center = TRUE, # Center by the mean
                    scannf = FALSE, # Don't plot
                    nf = 2) # Number of axis to keep 
```

#### Pull out scores for each species

```{r}
p1.score <- suprow(pca.env, dplyr::filter(ptExtracteddf, name == "Galax urceolata")[, 1:8])$li
p2.score <- suprow(pca.env, dplyr::filter(ptExtracteddf, name == "Pyxidanthera barbulata")[, 1:8])$li
p3.score <- suprow(pca.env, dplyr::filter(ptExtracteddf, name == "Pyxidanthera brevifolia")[, 1:8])$li
p4.score <- suprow(pca.env, dplyr::filter(ptExtracteddf, name == "Shortia galacifolia")[, 1:8])$li
scores.clim <- pca.env$li
```

##### Visualize

```{r}
plot(scores.clim, pch = 16, asp = 1,
     col = adjustcolor(1, alpha.f = 0.2), cex = 2,
     xlab = "PC1", ylab = "PC2") 
points(p1.score, pch = 18, col = pal[1], cex = 2)
points(p2.score, pch = 18, col = pal[2], cex = 2)
points(p3.score, pch = 18, col = pal[3], cex = 2)
points(p4.score, pch = 18, col = pal[4], cex = 2)
```

#### Kernel density estimates

Create occurrence density grids based on the ordination data.

```{r}
z1 <- ecospat.grid.clim.dyn(scores.clim, scores.clim, p1.score, R = 100)
z2 <- ecospat.grid.clim.dyn(scores.clim, scores.clim, p2.score, R = 100)
z3 <- ecospat.grid.clim.dyn(scores.clim, scores.clim, p3.score, R = 100)
z4 <- ecospat.grid.clim.dyn(scores.clim, scores.clim, p4.score, R = 100)
zlist  <- list(z1, z2, z3, z4)
```

#### Niche Overlap

Schoener's D ranges from 0 to 1. 0 represents no similarity between niche space. 1 represents completely identical niche space.

```{r}
overlapD <- matrix(ncol = 2, nrow = 7)
n <- 1
for(i in 1:3){
  for(j in 2:4){
    if(i != j){
      overlapD[n, 1]<- paste0("z", i, "-", "z", j)
      overlapD[n, 2]<- ecospat.niche.overlap(zlist[[i]], zlist[[j]], cor = TRUE)$D
      n <- n + 1
    }
  }
}

overlapDdf <- data.frame(overlapD)
overlapDdf
```

##### Niche Overlap Visualization

```{r}
par(mfrow=c(1,2))
ecospat.plot.niche.dyn(z1, z4, quant=0.25, interest = 1
                       , title= "Niche Overlap - Z1 top", name.axis1="PC1", name.axis2="PC2")
ecospat.plot.niche.dyn(z1, z4, quant=0.25, interest = 2
                       , title= "Niche Overlap - Z4 top", name.axis1="PC1", name.axis2="PC2")
```

#### Niche Equivalency Test

Based on Warren et al. 2008 - Are the two niche identical?\
Hypothesis test for D, null based on randomization. H1: the niche overlap is higher than expected by chance (or when randomized).

```{r}
eq.test <- ecospat.niche.equivalency.test(z1, z4, rep = 10, alternative = "greater")
ecospat.plot.overlap.test(eq.test, "D", "Equivalency")
```

#### Niche Similarity Test

Based on Warren et al. 2008 - Are the two niche similar?\
Can one species' niche predict the occurrences of a second species better than expected by chance?

```{r}
sim.test <- ecospat.niche.similarity.test(z1, z4, rep = 10, alternative = "greater", rand.type=2)
ecospat.plot.overlap.test(sim.test, "D", "Similarity")
```

## Ecological Niche Modeling

Ecological Niche Modeling in R.\
Modified and created by Anthony Melton and ML Gaynor.

This script is for generating and testing ENMs using ENMEval. Please see the [paper describing ENMEval](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13628) and their [vignette](https://jamiemkass.github.io/ENMeval/articles/ENMeval-2.0.0-vignette.html).

### Set up java memory

```{r}
options(java.parameters = "- Xmx16g") # increase memory that can be used
```

### Load Packages

```{r message=FALSE, warning=FALSE}
library(raster)
library(gtools)
library(dplyr)
library(dismo)
library(ENMeval)
library(ggplot2)
library(viridis)
```

### Load Function

```{r message=FALSE, warning=FALSE}
source("functions/ENMevaluation.R")
```

### Load data file

```{r}
alldf <- read.csv("data/cleaning_demo/maxent_ready/diapensiaceae_maxentready_20210625.csv")
```

#### Subset for each species

```{r}
Galax_urceolata <- dplyr::filter(alldf, name == "Galax urceolata")
Pyxidanthera_barbulata <- dplyr::filter(alldf, name == "Pyxidanthera barbulata")
Pyxidanthera_brevifolia <- dplyr::filter(alldf, name == "Pyxidanthera brevifolia")
Shortia_galacifolia <- dplyr::filter(alldf, name == "Shortia galacifolia")
```

### Raster layers

```{r}
list <- list.files("data/climate_processing/PresentLayers/all", full.names = TRUE, recursive = FALSE) 
list <- mixedsort(sort(list))
allstack <- stack(list)
```

#### Read in species training layers

```{r}
gstack <- stack(mixedsort(sort(list.files("data/climate_processing/PresentLayers/Galax_urceolata/", full.names = TRUE))))
pbastack <- stack(mixedsort(sort(list.files("data/climate_processing/PresentLayers/Pyxidanthera_barbulata/", full.names = TRUE))))
pbrstack <- stack(mixedsort(sort(list.files("data/climate_processing/PresentLayers/Pyxidanthera_brevifolia/", full.names = TRUE))))
sstack <- stack(mixedsort(sort(list.files("data/climate_processing/PresentLayers/Shortia_galacifolia/", full.names = TRUE))))
```

#### Fix projection

```{r}
projection(allstack) <- "+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs"
projection(gstack) <- "+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs"
projection(pbastack) <- "+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs"
projection(pbrstack) <- "+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs"
projection(sstack) <- "+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs"
```

### Model Generation

#### dismo Model Generations

Match MaxEnt GUI settings (see word document and powerpoint)

```{r message=FALSE, warning=FALSE}
evaldis <- dismo::maxent(x = gstack, p = Galax_urceolata[, c("long", "lat")], nbg = 10000,
                         args = c("projectionlayers=data/climate_processing/PresentLayers/all",
                                  "responsecurves", "jackknife",  
                                  "outputformat=logistic","randomseed", 
                                  "randomtestpoints=25",  "replicates=5", 
                                  "replicatetype=subsample",  "maximumiterations=5000",
                                  "writebackgroundpredictions","responsecurvesexponent",
                                  "writeplotdata"), 
                         removeDuplicates = TRUE
                         #,path = "data/Ecological_Niche_Modeling/enm_output/Galax_urceolata/"
              )
```

### ENMeval Model generation

ENMeval will generate multiple models and test them per the specified test method.Two important variables here are the regularization multiplier (RM) value and the feature class (FC). FC will allow for different shapes in response curves (linear, hinge, quadratic, product, and threshold) can be used in the model and RM will influence how many parameters are included in the model.

```{r message=FALSE, warning=FALSE, collapse = TRUE}
eval1 <- ENMeval::ENMevaluate(occ = Galax_urceolata[, c("long", "lat")], 
                              env = gstack,
                              tune.args = list(fc = c("L","Q"), rm = 1:2), 
                              partitions = "block",
                              n.bg = 10000,
                              parallel = FALSE,
                              algorithm = 'maxent.jar', 
                              user.eval = proc)
```

------------------------------------------------------------------------

### Model Statistics

#### dismo

Inspect the dismo model based on the html

```{r eval=FALSE}
browseURL(evaldis@html)

```

### ENMeval

Inspect the many models 

#### Visualize   

```{r}
maps <- eval1@predictions
plot(maps)
```

#### Look at model overlap   

```{r}
mod_overlap <- calc.niche.overlap(eval1@predictions, overlapStat = "D")
kable(mod_overlap) %>%
   kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
   scroll_box(width = "100%", height = "200px")
```

#### Inspect the results

Identify the best model selecting models with the lowest average test omission rate and the highest average validation AUC

```{r}
results <- eval.results(eval1)
opt.seq <- results %>% 
            dplyr::filter(or.10p.avg == min(or.10p.avg)) %>% 
            dplyr::filter(auc.val.avg == max(auc.val.avg))
kable(opt.seq)  %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
   scroll_box(width = "100%", height = "200px")

```

#### Subset model

```{r}
mod.seq <- eval.models(eval1)[[opt.seq$tune.args]]
```

#### Inspect

```{r}
kable(mod.seq@results) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
  scroll_box(width = "100%", height = "200px")
```

#### Look at variable contribution

```{r}
plot(mod.seq)
```

#### Look at the response curves

```{r message=FALSE, warning=FALSE}
dismo::response(mod.seq)
```

#### Project model to allstack

```{r}
p <- predict(mod.seq, allstack) 
```

#### Visualize

```{r}
# Make into a data frame
p_df <-  as.data.frame(p, xy = TRUE)

# Plot
ggplot() +
  geom_raster(data = p_df, aes(x = x, y = y, fill = layer)) +
  geom_point(data= Galax_urceolata, 
             mapping = aes(x = long, y = lat), 
             col='red', cex=0.05) +
  coord_quickmap() +
  theme_bw() + 
  scale_fill_gradientn(colours = viridis::viridis(99),
                       na.value = "black")

```

------------------------------------------------------------------------

### Save outputs

#### R saved dataset

```{r}
save(mod.seq, file = "data/Ecological_Niche_Modeling/enm_output/ENMeval/GalaxENM.rda")
```

#### Save Raster

```{r}
writeRaster(x = p, filename = "data/Ecological_Niche_Modeling/enm_output/ENMeval/GalaxENM.asc",
            format = "ascii", NAFlag = "-9999", overwrite = T)
```

## ENM Processing

Processing Ecological Niche Models in R.\
Script by Anthony Melton and ML Gaynor.

### Load Packages

```{r message=FALSE, warning=FALSE}
library(raster)
library(gtools)
library(dplyr)
library(ENMTools)
library(ENMeval)
library(ape)
library(RStoolbox)
library(hypervolume)
library(phytools)
```

### Load functions

The following command generates a binary predicted occurrence map. This was written by Anthony Melton. 

```{r}
source("functions/Functions_AEM.R")
```

### Read in models you generated with the MaxEnt GUI into R.

```{r}
sp1_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Galax_urceolata_avg.asc")
sp2_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Pyxidanthera_barbulata_avg.asc")
sp3_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Pyxidanthera_brevifolia_avg.asc")
sp4_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Shortia_galacifolia_avg.asc")
```

### Read in Bioclim layers

These steps are described in the previous script

```{r}
system("rm -rf data/climate_processing/PresentLayers/all/maxent.cache/")
list <- list.files("data/climate_processing/PresentLayers/all/", 
                   full.names = TRUE, recursive = FALSE) 
list <- mixedsort(sort(list))
allstack <- stack(list)
projection(allstack) <- "+proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs"
```

------------------------------------------------------------------------

### ENM Breadth

Niche breadth is the breadth of environmental factors for a species' niche, ranging from 0 to 1. When breadth is closer to 1 the more generalist species with wider tolerances. Values closer to 0 indicate a more specialized species. The raster.breadth command in ENMTools measures the smoothness of suitability scores across a projected landscape. The higher the score, the more of the available niche space a species occupies.

```{r}
sp1_breadth <- ENMTools::raster.breadth(x = sp1_enm.mx.b)
sp1_breadth$B2
sp2_breadth <- ENMTools::raster.breadth(x = sp2_enm.mx.b)
sp2_breadth$B2
sp3_breadth <- ENMTools::raster.breadth(x = sp3_enm.mx.b)
sp3_breadth$B2
sp4_breadth <- ENMTools::raster.breadth(x = sp4_enm.mx.b)
sp4_breadth$B2
```

### ENM Overlap

Calculating niche overlap, Schoener's D, with ENMEval - Schoener's D ranges from 0 to 1, where 0 represents no similarity between the projections and 1 represents completely identical projections.

#### Stack the projections and make sure the stack is named.

```{r}
enm_stack.b <- stack(sp1_enm.mx.b, sp2_enm.mx.b, sp3_enm.mx.b, sp4_enm.mx.b)
names(enm_stack.b) <- c("Galax urceolata", "Pyxidanthera barbulata",  "Pyxidanthera brevifolia","Shortia galacifolia" )
```

#### Calculate

```{r}
calc.niche.overlap(enm_stack.b, overlapStat = "D")
```

------------------------------------------------------------------------

### Phylogenetic correlations

Let's look at niche overlap over a tree!   


#### Load the tree file  

```{r}
tree <- ape::read.tree(file = 
                         "data/Ecological_Niche_Modeling/AOC_Test_Demo/diapensiaceae_subset.tre")
tree <- ape::compute.brlen(phy = tree, method = "grafen")
plot(tree)
```

#### Drop the outgroup

```{r}
tree <- drop.tip(tree, "Cyrilla_racemiflora")
plot(tree)
```

#### Generate species objects for each tree member!

```{r}
sp1 <- enmtools.species(species.name = "Galax_urceolata",
                        presence.points = Galax_urceolata[,3:2])
sp1$range <- background.raster.buffer(sp1$presence.points, 25000, mask = allstack)
sp1$background.points = background.points.buffer(points = sp1$presence.points, radius = 5000, n = 10000, mask =  allstack[[1]])
##############################
sp2 <- enmtools.species(species.name = "Pyxidanthera_barbulata",
                                        presence.points = Pyxidanthera_barbulata[,3:2])
sp2$range <- background.raster.buffer(sp2$presence.points, 25000, mask = allstack)
sp2$background.points = background.points.buffer(points = sp2$presence.points, radius = 5000, n = 10000, mask =  allstack[[1]])
#############################
sp3 <- enmtools.species(species.name = "Pyxidanthera_brevifolia",
                                        presence.points = Pyxidanthera_brevifolia[,3:2])
sp3$range <- background.raster.buffer(sp3$presence.points, 25000, mask = allstack)
sp3$background.points = background.points.buffer(points = sp3$presence.points, radius = 5000, n = 10000, mask =  allstack[[1]])
#############################
sp4 <- enmtools.species(species.name = "Shortia_galacifolia",
                                          presence.points = Shortia_galacifolia[,3:2])
sp4$range <- background.raster.buffer(sp4$presence.points, 25000, mask = allstack)
sp4$background.points = background.points.buffer(points = sp4$presence.points, radius = 5000, n = 10000, mask =  allstack[[1]])
```

#### Create "clade" object with all the species in the tree

```{r message=FALSE, warning=FALSE, collapse = TRUE}
clade=enmtools.clade(species = list(sp1, sp2, sp3, sp4), tree = tree)
check.clade(clade)
```

#### Age-Range Correlation Test

```{r}
range.aoc <- enmtools.aoc(clade = clade,  nreps = 10, overlap.source = "range")
summary(range.aoc)
```

#### Age-Overlap Correlation Test

```{r}
glm.aoc <- enmtools.aoc(clade = clade,  env = allstack, nreps = 10, overlap.source = "glm")
summary(glm.aoc)
```

The results here are pretty meaningless since we're looking at very few species, but it serves the purpose of the demo. For range AOCs, an intercept \>0.5 and negative slope are indicative of sympatric species, while an intercept of \<0.5 and a positive slope are indicative on non-sympatric speciation. A low intercept and positive slope for niche overlap would indicate niche divergence. \*\*\*

### Hypervolume

This will generate a binary map with any cell that contains a suitability score greater than or equal to the lowest score with an occurrence point as a presence. There are other ways to set the threshold, including percentiles or training statistics.

#### Load occurrence data

```{r}
alldf <- read.csv("data/cleaning_demo/maxent_ready/diapensiaceae_maxentready_20210625.csv")
```

#### Subset for each species

```{r}
Galax_urceolata <- dplyr::filter(alldf, name == "Galax urceolata")
Pyxidanthera_barbulata <- dplyr::filter(alldf, name == "Pyxidanthera barbulata")
Pyxidanthera_brevifolia <- dplyr::filter(alldf, name == "Pyxidanthera brevifolia")
Shortia_galacifolia <- dplyr::filter(alldf, name == "Shortia galacifolia")
```

#### Create the binary maps

```{r}
sp1.dist <- make.binary.map(model = sp1_enm.mx.b, occ.dat = Galax_urceolata)
sp2.dist <- make.binary.map(model = sp2_enm.mx.b, occ.dat = Pyxidanthera_barbulata)
sp3.dist <- make.binary.map(model = sp3_enm.mx.b, occ.dat = Pyxidanthera_brevifolia)
sp4.dist <- make.binary.map(model = sp4_enm.mx.b, occ.dat = Shortia_galacifolia)
```

#### Plot

```{r}
par(mfrow = c(2,2),  mar = c(1,1,1,1))
plot(sp1.dist)
plot(sp2.dist)
plot(sp3.dist)
plot(sp4.dist)
```

#### Hypervolume

Next, let's work on getting some data from the predicted distributions! Niche space can be thought of as a multi-dimensional hypervolume. We're using climatic data in this case, so we're measuring the hypervolume of climatic niche space occupied by these species.\
**Warning: This takes forever!**

```{r eval=FALSE}
sp1.hv <- get_hypervolume(binary_projection = sp1.dist, envt = allstack)
sp2.hv <- get_hypervolume(binary_projection = sp2.dist, envt = allstack)
sp3.hv <- get_hypervolume(binary_projection = sp3.dist, envt = allstack)
sp4.hv <- get_hypervolume(binary_projection = sp4.dist, envt = allstack)
```

#### Compare the hypervolumes

```{r eval=FALSE}
hv_set <- hypervolume_set(hv1 = sp1.hv, hv2 = sp2.hv, check.memory = F)
hypervolume_overlap_statistics(hv_set)
plot(hv_set)
get_volume(hv_set)
```

## Phylogenetic Diversity

Original script by J. Janzten.    
Modified by ML Gaynor.    

### Load Packages

```{r message=FALSE, warning=FALSE}
library(raster)
library(ape)
library(phytools)
library(picante)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(rgdal)
library(rgeos)
library(sp)
```

### Load the tree file

```{r}
tree <- ape::read.tree(file = "data/Ecological_Niche_Modeling/AOC_Test_Demo/diapensiaceae_subset.tre")
tree <- ape::compute.brlen(phy = tree, method = "grafen")
plot(tree)
```

#### Drop the outgroup

```{r}
tree <- drop.tip(tree, "Cyrilla_racemiflora")
```

### Read ENM models

```{r}
sp1_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Galax_urceolata_avg.asc")
sp2_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Pyxidanthera_barbulata_avg.asc")
sp3_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Pyxidanthera_brevifolia_avg.asc")
sp4_enm.mx.b <- raster("data/Ecological_Niche_Modeling/enm_output/Shortia_galacifolia_avg.asc")
```

### Reclassify rasters

```{r}
reclassify_raster <- function(OGraster){
  ## Reclassify the raster by the suitability score
  OGraster[OGraster >= 0.25] <- 1
  OGraster[OGraster < 0.25] <- 0
  OGraster[is.na(OGraster)] <- 0
  crs(OGraster) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
  return(OGraster)
}
```

```{r}
sp1_enm.mx.b  <- reclassify_raster(sp1_enm.mx.b)
sp2_enm.mx.b  <- reclassify_raster(sp2_enm.mx.b)
sp3_enm.mx.b  <- reclassify_raster(sp3_enm.mx.b)
sp4_enm.mx.b  <- reclassify_raster(sp4_enm.mx.b)
```

#### Inspect the reclassified layers

```{r}
par(mfrow=c(2,2))
plot(sp1_enm.mx.b)
plot(sp2_enm.mx.b)
plot(sp3_enm.mx.b)
plot(sp4_enm.mx.b)
```

### Stack rasters and create dataframe

```{r}
enm_stack <- stack(sp1_enm.mx.b, sp2_enm.mx.b, sp3_enm.mx.b, sp4_enm.mx.b)
names(enm_stack) <- c("Galax_urceolata", "Pyxidanthera_barbulata",  "Pyxidanthera_brevifolia","Shortia_galacifolia" )
```

#### Convert to dataframe

```{r}
rasterstack_df <- as.data.frame(enm_stack, xy = TRUE)
```

### Extract Ecoregions for points

#### Load USA shapefile

Obtained at <https://www.epa.gov/eco-research/level-iii-and-iv-ecoregions-continental-united-states>

```{r}
shp <- ("data/phylogenetic_diversity/USraster/us_eco_l4/us_eco_l4_no_st.shp")
USAshape <- readOGR(shp, layer="us_eco_l4_no_st")
```

#### Correct CRS

```{r}
newcrs <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
USAshape2 <- spTransform(USAshape, newcrs)
```

### Convert dataframe to points

```{r}
df.sp <- rasterstack_df[,1:2]
coordinates(df.sp)<-~x+y
crs(df.sp) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"
```

### Extract points from shapefile

**Warning: this will take a while!!**

```{r}
df.sp.info <- sp::over(df.sp, USAshape2)
```

### Bind dataframe with points and with ecosystems

```{r}
rasterstack_df.info <- cbind(df.sp.info, rasterstack_df)
rasterstack_df.info2 <- rasterstack_df.info %>%
                        dplyr::group_by(L4_KEY) %>% 
                        dplyr::summarize(Galax_urceolata = max(Galax_urceolata),
                                         Pyxidanthera_barbulata = max(Pyxidanthera_barbulata),
                                         Pyxidanthera_brevifolia = max(Pyxidanthera_brevifolia), 
                                         Shortia_galacifolia = max(Shortia_galacifolia))
rasterstack_df.info2df <- as.data.frame(rasterstack_df.info2, row.names = FALSE)
```

#### Removing NA

```{r}
rasterstack_df.info4 <- rasterstack_df.info2df[1:137,]
```

#### Removing the first column

```{r}
rasterstack_df.info3 <- rasterstack_df.info4[,-1]
```

#### Renaming the rows

```{r}
row.names(rasterstack_df.info3) <- NULL
row.names(rasterstack_df.info3) <- rasterstack_df.info4[,1]

kable(rasterstack_df.info3)%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
  scroll_box(width = "100%", height = "200px")
```

------------------------------------------------------------------------

### Phylogenetic Diversity Calculations

#### Match tree and dataframe

```{r}
matched <- match.phylo.comm(tree, rasterstack_df.info3)
```

#### Make object for tree including matching taxa only (non-matching taxa will be pruned out)

```{r}
matchtree <- matched$phy
```

#### Make object for dataset including matching taxa only (non-matching taxa removed)

```{r}
matchcomm <- matched$comm 
```

#### Calculate phylogenetic distance matrix for use in MPD and MNTD calculations

MPD stands for mean pairwise distance, or mean phylogenetic distance among all pairs of species within a community. MNTD stands for mean nearest taxon distance, or the mean distance between each species within a community and its closest relative.

```{r}
phydist <- cophenetic(matched$phy)
```

#### Calculate indices using picante

Null model options include taxa.labels (shuffle tips of phylogeny) among others. Use ses.pd, ses.mpd and ses.mntd for more info on alternative null models and other parameters and output format. Number of runs - only using 99 runs (comparing to null model) due to time constraints.

##### PD calculates Faith's PD and standard effect size of PD

PD stands for phylogenetic diversity

```{r}
pd_result <-ses.pd(matchcomm, matchtree, null.model="taxa.labels", runs=99)
```

#### Calculates mpd and ses mpd - equivalent to -NRI

NRI stands for net-relatedness index, standardizes MPD or mean pairwise distance. ses stands for standardized effect size. If we had abundance data, we could include that for mpd and mntd. The default is abundance.weighted = FALSE.

```{r}
mpd_result <- ses.mpd(matchcomm, phydist, null.model="taxa.labels", abundance.weighted = FALSE, runs=99)
```

#### Calculates mntd and ses mntd - equivalent to -NTI

NTI stands for nearest taxon index, standardizes MNTD mean nearest taxon distance. ses stands for standardized effect size.

```{r}
mntd_result <- ses.mntd(matchcomm, phydist, null.model="taxa.labels", runs=99)
```

### Look at results

Positive ses values (obs.z values) and p values \> 0.95 indicate overdispersion (greater than expected).Negative ses values (obs.z values) and p values \< 0.05 indicate clustering (less than expected). Values not significantly different from zero indicate taxa in community randomly distributed across tree.

```{r}
kable(pd_result) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
  scroll_box(width = "100%", height = "200px")
```

```{r}
kable(mpd_result) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
  scroll_box(width = "100%", height = "200px")

```

```{r}
kable(mntd_result) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 10)) %>%
  scroll_box(width = "100%", height = "200px")

```

#### Plot PD results by community

```{r}
ggplot() +
  geom_point(data = pd_result, aes(x = rownames(pd_result), y = pd.obs, col = pd.obs)) +
  ggtitle("PD values by ecoregion") +
  xlab("Community") + 
  ylab("PD") +
  theme(text = element_text(size=10), axis.text.x = element_text(angle = 90, hjust = 1))
```

#### Plot MPD results by community

```{r}
ggplot()+
  geom_point(data = mpd_result, aes(x = rownames(mpd_result), y = mpd.obs, col = mpd.obs))+
  ggtitle("MPD values by ecoregion")+
  xlab("Community")+
  ylab("MPD")+
  theme(text = element_text(size=10), axis.text.x = element_text(angle = 90, hjust = 1))
```

#### Plot MNTD results by community

```{r}
ggplot()+
  geom_point(data = mntd_result, aes(x = rownames(mntd_result), y = mntd.obs, col = mntd.obs))+
  ggtitle("MNTD values by ecoregion")+
  xlab("Community")+
  ylab("MNTD")+
  theme(text = element_text(size=10), axis.text.x = element_text(angle = 90, hjust = 1))
```
